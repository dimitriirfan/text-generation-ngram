# text-generation-ngram

We can train a N gram language model on a corpus and assign the probability of a word appearing given the previous word, that way we can generate a word by predicting the most likely word that can exist given a previous word.

In this notebook I will train my N Gram model to generate a word that can talk like Shakespeare by training the model in shakespeare dataset.


## Example generated sentence
```
'what art thou come why my cheese my digestion why hast thou thus adjournd the graces for his merits due being all to'
```
